{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Train NF-ResNet on Cifar-10 using PyTorch Lightning",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quanganh1999/NF-Net-on-CIFAR/blob/main/Train_NF_ResNet_on_Cifar_10_using_PyTorch_Lightning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MirDQLgiwyi2"
      },
      "source": [
        "## ⚙️ Imports and Setups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3YQexR3oZm8"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQUxq6oRtUP9",
        "outputId": "7e258c5c-171e-46fb-f0b8-7edc3f5434da"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Qo4vWV4NbiO",
        "outputId": "d5f98eac-f443-46e4-e286-f7c3db29276d"
      },
      "source": [
        "%cd drive/MyDrive/NF-Resnet"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/NF-Resnet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evscgXTFwszZ"
      },
      "source": [
        "%%capture\n",
        "# Install pytorch lighting\n",
        "!pip install pytorch-lightning --quiet\n",
        "# Install weights and biases\n",
        "!pip install wandb --quiet"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ugRAnKKYtzU",
        "outputId": "6773078d-53e3-4dec-f7e4-019a362ae4df"
      },
      "source": [
        "!pip install lightning-bolts[\"extra\"] --quiet"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 256kB 7.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 22.3MB 97kB/s \n",
            "\u001b[K     |████████████████████████████████| 37.6MB 146kB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX7QXaoVz3OC"
      },
      "source": [
        "!git clone https://github.com/rwightman/pytorch-image-models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSsjHKVnd2Dg"
      },
      "source": [
        "!pip install git+https://github.com/rwightman/pytorch-image-models.git --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieJ6Kl7ixBFT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "54db757d-f492-4778-9569-7046bddf8414"
      },
      "source": [
        "# regular imports\n",
        "import sys\n",
        "sys.path.append(\"pytorch-image-models\")\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "# pytorch related imports \n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.datasets.utils import download_url\n",
        "\n",
        "# import for nfnet\n",
        "import timm\n",
        "from timm.utils import *\n",
        "from timm.models import model_parameters\n",
        "\n",
        "# lightning related imports\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.metrics.functional import accuracy\n",
        "from pytorch_lightning.callbacks import Callback\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "# sklearn related imports\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# import wandb and login\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IcAjtkapCav"
      },
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision.datasets import CIFAR10\n",
        "from pytorch_lightning.utilities.seed import seed_everything\n",
        "import pl_bolts"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKp7sN7IDHcz",
        "outputId": "519e0d4d-55f9-4ec5-e889-2d5d5c76ed7a"
      },
      "source": [
        "seed_everything(1999)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 1999\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ySyjhUdk6oM"
      },
      "source": [
        "## Create base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oFHRgPMk54t"
      },
      "source": [
        "base_model = timm.create_model(\"eca_nfnet_l1\", pretrained=True) #256 input 320 test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TYkiZc_lFx0"
      },
      "source": [
        "config = base_model.default_cfg\n",
        "config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_11_ucfHiXN"
      },
      "source": [
        "## 🎨 Using DataModules - `Clatech101DataModule`\n",
        "\n",
        "DataModules are a way of decoupling data-related hooks from the `LightningModule` so you can develop dataset agnostic models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajVx05kWjCNo"
      },
      "source": [
        "class CIFAR10Data(pl.LightningDataModule):\n",
        "      def __init__(self, batch_size, data_dir: str = './'):\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size        \n",
        "        self.mean = (0.4914, 0.4822, 0.4465)\n",
        "        self.std = (0.2471, 0.2435, 0.2616)\n",
        "\n",
        "        #augmentation (use other strong augmentation)\n",
        "        # self.train_transform = transforms.Compose(\n",
        "        #     [\n",
        "        #         transforms.RandomCrop(32, padding=4),\n",
        "        #         transforms.RandomHorizontalFlip(),\n",
        "        #         transforms.ToTensor(),\n",
        "        #         transforms.Normalize(self.mean, self.std),\n",
        "        #     ]\n",
        "        # )\n",
        "\n",
        "        #typical resize\n",
        "        # self.train_transform = transforms.Compose([\n",
        "        #   transforms.RandomResizedCrop((256, 256), scale=(0.05, 1.0)),\n",
        "        #   transforms.ToTensor(),\n",
        "        #   transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "        # ])\n",
        "\n",
        "        #timm resize\n",
        "        self.train_transform = timm.data.transforms_factory.transforms_imagenet_train(\n",
        "            img_size = 256,            \n",
        "            scale = (0.05, 1.0),\n",
        "            interpolation=config[\"interpolation\"],\n",
        "            mean=config[\"mean\"],\n",
        "            std=config[\"std\"]            \n",
        "        )\n",
        "   \n",
        "        #need to resize for more acc ??\n",
        "        # self.test_transform = transforms.Compose(\n",
        "        #     [\n",
        "        #         transforms.ToTensor(),\n",
        "        #         transforms.Normalize(self.mean, self.std),\n",
        "        #     ]\n",
        "        # )\n",
        "\n",
        "        #typical resize\n",
        "        # self.test_transform = transforms.Compose([\n",
        "        # transforms.Resize((320, 320)),\n",
        "        # transforms.ToTensor(),\n",
        "        # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "        # ])\n",
        "\n",
        "        #timm resize\n",
        "        self.test_transform = timm.data.transforms_factory.transforms_imagenet_eval(\n",
        "            img_size = 320,\n",
        "            interpolation=config[\"interpolation\"],\n",
        "            mean=config[\"mean\"],\n",
        "            std=config[\"std\"],\n",
        "            crop_pct=config[\"crop_pct\"]\n",
        "        )\n",
        "\n",
        "        # self.dims = (3, 32, 32)\n",
        "        self.num_classes = 10\n",
        "\n",
        "      def prepare_data(self):\n",
        "        # download \n",
        "        CIFAR10(self.data_dir, train=True, download=True)\n",
        "        CIFAR10(self.data_dir, train=False, download=True)    \n",
        "\n",
        "      def setup(self, stage=None):        \n",
        "        if stage == 'fit' or stage is None:\n",
        "            # load the dataset    \n",
        "            self.cifar_full_train = CIFAR10(self.data_dir, train=True, transform=self.train_transform)\n",
        "            self.cifar_full_val = CIFAR10(self.data_dir, train=True, transform=self.test_transform)             \n",
        "            num_train = len(self.cifar_full_train)\n",
        "            indices = list(range(num_train))\n",
        "            split = int(np.floor(0.1 * num_train))\n",
        "            np.random.seed(1999)\n",
        "            np.random.shuffle(indices)\n",
        "\n",
        "            #train\n",
        "            train_idx, valid_idx = indices[split:], indices[:split]\n",
        "            self.train_sampler = SubsetRandomSampler(train_idx)\n",
        "            self.valid_sampler = SubsetRandomSampler(valid_idx)            \n",
        "\n",
        "        # Assign test dataset for use in dataloader(s)\n",
        "        if stage == 'test' or stage is None:\n",
        "            self.cifar_test = CIFAR10(self.data_dir, train=False, transform=self.test_transform)        \n",
        "\n",
        "      def train_dataloader(self):\n",
        "        #return DataLoader(self.cifar_full_train, batch_size=self.batch_size, sampler=self.train_sampler)\n",
        "        return DataLoader(self.cifar_full_train, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "      def val_dataloader(self):      \n",
        "        #return DataLoader(self.cifar_full_val, batch_size=self.batch_size, sampler=self.valid_sampler)\n",
        "        return DataLoader(self.cifar_test, batch_size=self.batch_size)\n",
        "\n",
        "      def test_dataloader(self):\n",
        "        return DataLoader(self.cifar_test, batch_size=self.batch_size)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkeBFJBkYJr1"
      },
      "source": [
        "## 📲 Callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBz4YZvYg-jc"
      },
      "source": [
        "#### 🚏 Earlystopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9gvY3pfYLOm"
      },
      "source": [
        "early_stop_callback = EarlyStopping(\n",
        "   monitor='val_loss',\n",
        "   patience=3,\n",
        "   verbose=False,\n",
        "   mode='min'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dhQJeOXhAmC"
      },
      "source": [
        "#### 🛃 Custom Callback - `ImagePredictionLogger`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GdiZ0b2FTfF"
      },
      "source": [
        "class ImagePredictionLogger(Callback):\n",
        "    def __init__(self, val_samples, num_samples=32):\n",
        "        super().__init__()\n",
        "        self.num_samples = num_samples\n",
        "        self.val_imgs, self.val_labels = val_samples\n",
        "        \n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
        "        val_labels = self.val_labels.to(device=pl_module.device)\n",
        "       \n",
        "        logits = pl_module(val_imgs)\n",
        "        preds = torch.argmax(logits, -1)\n",
        "        \n",
        "        trainer.logger.experiment.log({\n",
        "            \"examples\":[wandb.Image(x, caption=f\"Pred:{pred}, Label:{y}\") \n",
        "                           for x, pred, y in zip(val_imgs[:self.num_samples], \n",
        "                                                 preds[:self.num_samples], \n",
        "                                                 val_labels[:self.num_samples])]\n",
        "            })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpqnhW1xFAGH"
      },
      "source": [
        "#### 💾 Model Checkpoint Callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUiYNQbEG01y"
      },
      "source": [
        "MODEL_CKPT_PATH = './model'\n",
        "# MODEL_CKPT = 'model-{epoch:02d}-{val_loss:.2f}'\n",
        "MODEL_CKPT = 'model1-{epoch:02d}-{val_acc:.3f}'\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor='val_acc',\n",
        "    dirpath = MODEL_CKPT_PATH,\n",
        "    filename=MODEL_CKPT,\n",
        "    save_top_k=3,\n",
        "    save_last = True,\n",
        "    mode='max')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AegEWlwjS7Gv"
      },
      "source": [
        "## 🎺 Define The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKBN_rFfP0mL"
      },
      "source": [
        "class LitModel(pl.LightningModule):\n",
        "    #Empirically, when using adam optimizer, it is recommended to set learning_rate to 2e-4 \n",
        "    def __init__(self, input_shape, num_classes, learning_rate=1e-3, used_agc = False, clip_grad = 0.01):\n",
        "        super().__init__()\n",
        "        \n",
        "        # log hyperparameters\n",
        "        self.save_hyperparameters()\n",
        "        self.learning_rate = learning_rate\n",
        "        self.dim = input_shape\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        #train from scratch\n",
        "        # self.classifier = timm.create_model('nf_resnet50', pretrained=False, num_classes = num_classes)\n",
        "\n",
        "        #transfer learning\n",
        "        #fine-tuning\n",
        "        self.model = timm.create_model(\"eca_nfnet_l1\", pretrained=True, num_classes=num_classes) #256 input 320 test\n",
        "\n",
        "        #feature exactor (freezee all layers except the last layer)\n",
        "        # self.model = timm.create_model(\"eca_nfnet_l1\", pretrained=True)        \n",
        "        # for param in self.model.parameters():\n",
        "        #     param.requires_grad = False\n",
        "        # self.model.reset_classifier(num_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "      x = F.log_softmax(self.model.forward(x), dim=1)\n",
        "      return x\n",
        "\n",
        "    #using Adaptive Gradient Descent\n",
        "    #adapt from train procedure of timm package: https://github.com/rwightman/pytorch-image-models/blob/master/train.py        \n",
        "    #clip_grad: clipping factor\n",
        "    def on_after_backward(self):\n",
        "      if(self.used_agc):\n",
        "        dispatch_clip_grad(model_parameters(self.model, exclude_head = True),\n",
        "                           value = clip_grad, mode = \"agc\")\n",
        "\n",
        "    # logic for a single training step\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "        \n",
        "        # training metrics\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        acc = accuracy(preds, y)\n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True)\n",
        "        self.log('train_acc', acc, on_step=True, on_epoch=True, logger=True)\n",
        "        \n",
        "        return loss\n",
        "\n",
        "    # logic for a single validation step\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "\n",
        "        # validation metrics\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        acc = accuracy(preds, y)\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "        self.log('val_acc', acc, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    # logic for a single testing step\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "        \n",
        "        # validation metrics\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        acc = accuracy(preds, y)\n",
        "        self.log('test_loss', loss, prog_bar=True)\n",
        "        self.log('test_acc', acc, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=self.learning_rate, momentum=0.9, weight_decay=1e-6, nesterov = True)\n",
        "        #Because of using pretrain model, we should turn off warm up when using AGC\n",
        "        if(self.used_agc is False):\n",
        "          scheduler = pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR(optimizer, warmup_epochs = 5, max_epochs = 60)\n",
        "        else:\n",
        "          scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 60)        \n",
        "        #return optimizer\n",
        "        return [optimizer], [scheduler]\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceYFNcOuh9fP"
      },
      "source": [
        "## ⚡ Train and Evaluate The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvY-POwDT3Fi"
      },
      "source": [
        "# Init our data pipeline\n",
        "BATCH_SIZE = 256\n",
        "dm = CIFAR10Data(batch_size=BATCH_SIZE)\n",
        "# To access the x_dataloader we need to call prepare_data and setup.\n",
        "dm.prepare_data()\n",
        "dm.setup()\n",
        "\n",
        "# Samples required by the custom ImagePredictionLogger callback to log image predictions.\n",
        "val_samples = next(iter(dm.val_dataloader()))\n",
        "val_imgs, val_labels = val_samples[0], val_samples[1]\n",
        "val_imgs.shape, val_labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjZi8Ya-fAa9"
      },
      "source": [
        "# Init our model\n",
        "model = LitModel(input_shape=(3, 256, 256), num_classes = 10, , used_agc=True, clip_grad=0.015)\n",
        "\n",
        "# Initialize wandb logger\n",
        "wandb_logger = WandbLogger(project='nfnet', job_type='train-nf-resnet')\n",
        "\n",
        "# Initialize a trainer\n",
        "trainer = pl.Trainer(max_epochs=60,\n",
        "                     progress_bar_refresh_rate=5, \n",
        "                     gpus=1, \n",
        "                     logger=wandb_logger,\n",
        "                     #early_stop_callback,                     \n",
        "                     callbacks=[ImagePredictionLogger(val_samples), checkpoint_callback]\n",
        "                     )\n",
        "\n",
        "# Train the model ⚡🚅⚡\n",
        "trainer.fit(model, dm) \n",
        "\n",
        "# Evaluate the model on the held out test set ⚡⚡\n",
        "trainer.test()\n",
        "\n",
        "# Close wandb run\n",
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaPgH28gLskz"
      },
      "source": [
        "#resume from checkpoint:\n",
        "model = LitModel((3, 256, 256), 10)\n",
        "\n",
        "# Initialize wandb logger\n",
        "wandb_logger = WandbLogger(project='nfnet', job_type='train-nf-resnet')\n",
        "\n",
        "# Initialize a trainer\n",
        "trainer = pl.Trainer(max_epochs=60,\n",
        "                     progress_bar_refresh_rate=5, \n",
        "                     gpus=1, \n",
        "                     logger=wandb_logger,\n",
        "                     #early_stop_callback,\n",
        "                     callbacks=[ImagePredictionLogger(val_samples), checkpoint_callback],\n",
        "                     resume_from_checkpoint='model/last.ckpt'\n",
        "                     )\n",
        "\n",
        "# Train the model ⚡🚅⚡\n",
        "trainer.fit(model, dm) \n",
        "\n",
        "# Evaluate the model on the held out test set ⚡⚡\n",
        "trainer.test()\n",
        "\n",
        "# Close wandb run\n",
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp8V5XjKoQEc"
      },
      "source": [
        "#Test with checkpoint\n",
        "LitModel((3, 32, 32), 10)\n",
        "model = LitModel.load_from_checkpoint(checkpoint_path='./model/model2-epoch=41-val_acc=0.974.ckpt')\n",
        "\n",
        "# init trainer with whatever options\n",
        "trainer = trainer = pl.Trainer(gpus=1)\n",
        "\n",
        "# test (pass in the model)\n",
        "trainer.test(model, datamodule = dm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1FjXlc9ogTh"
      },
      "source": [
        "%ls model/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEhB5NogaJho"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}